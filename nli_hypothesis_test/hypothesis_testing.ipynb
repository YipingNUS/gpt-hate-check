{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152ec741",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.notebook import tnrange, tqdm\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import  torch\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "    \n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8cbf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "negation_words = set([\"no\", \"not\", \"never\", \"neither\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8270ae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "nli_model_checkpoint = \"facebook/bart-large-mnli\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(nli_model_checkpoint\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(nli_model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7715cbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_single_hypothesis(premise, hypothesis, target_group=None, mask_token=\"[X]\"):\n",
    "    if target_group:  # target_group not none\n",
    "        hypothesis = hypothesis.replace(mask_token, target_group)\n",
    "    # run through model pre-trained on MNLI\n",
    "    x = tokenizer.encode(premise, hypothesis, return_tensors='pt', truncation='only_first')\n",
    "    with torch.no_grad():\n",
    "        logits = model(x.to(device))[0]\n",
    "    # we throw away \"neutral\" (dim 1) and take the probability of\n",
    "    # \"entailment\" (2) as the probability of the label being true \n",
    "    entail_contradiction_logits = logits[:,[0,2]]\n",
    "    probs = entail_contradiction_logits.softmax(dim=1)\n",
    "    return probs[:,1].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96710c0",
   "metadata": {},
   "source": [
    "## 0. Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43db01ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(\"../datasets/gpt3.5-generated\")\n",
    "output_folder = Path(\"output/\")\n",
    "\n",
    "# TODO: changeme\n",
    "target_group = \"women\"  # options: \"black people\", \"Muslims\", \"disabled people\", \"gays\", \"immigrants\", \"trans\", \"women\"\n",
    "data_file = f\"dataset_{target_group}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012669fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (output_folder/data_file).is_file():\n",
    "    df = pd.read_csv(output_folder/data_file)\n",
    "else:\n",
    "    df = pd.read_csv(data_folder/data_file)\n",
    "df.drop_duplicates(subset=[\"message\"], keep='first', inplace=True, ignore_index=True)\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc867a6c",
   "metadata": {},
   "source": [
    "## 1. General hypothesis tests\n",
    "### A. Identity hypothesis test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4633834",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = \"That example is about [X].\"\n",
    "result = list()\n",
    "for tup in tqdm(df.itertuples(), total=df.shape[0]):\n",
    "    message, functionality, hate_label = tup[1], tup[2], tup[3]\n",
    "    prob = test_single_hypothesis(message, hypothesis, target_group=target_group)\n",
    "    result.append(int(prob > 0.5))\n",
    "df['nli_identity'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df54138",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_folder/data_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cf3232",
   "metadata": {},
   "source": [
    "### B. Hate hypothesis test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a3c178",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = \"That contains hate speech.\"\n",
    "result = list()\n",
    "for tup in tqdm(df.itertuples(), total=df.shape[0]):\n",
    "    message, functionality, hate_label = tup[1], tup[2], tup[3]\n",
    "    prob = test_single_hypothesis(message, hypothesis)\n",
    "    result.append(int(prob > 0.5))\n",
    "df['nli_hate'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d2cd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a message is hate speech if it mentions the identity and it's hateful\n",
    "df['nli_hate_label'] = df.apply(lambda x: int(x['nli_identity'] and x['nli_hate']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a069468",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_folder/data_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d123514",
   "metadata": {},
   "source": [
    "## 2. Functionality-Level Hypothesis Tests\n",
    "### F1: Expression of strong negative emotions (explicit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7b0bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = \"That text contains expression of strong negative emotions.\"\n",
    "func = \"F1: Expression of strong negative emotions (explicit)\"\n",
    "result = list()\n",
    "for tup in tqdm(df.itertuples(), total=df.shape[0]):\n",
    "    message, functionality, hate_label = tup[1], tup[2], tup[3]\n",
    "    if functionality == func:  # only apply to the target functionality\n",
    "        prob = test_single_hypothesis(message, hypothesis)\n",
    "        result.append(int(prob > 0.5))\n",
    "    else:\n",
    "        result.append(-1)\n",
    "df['nli_f1_neg_emotion'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47372b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_folder/data_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c43a53",
   "metadata": {},
   "source": [
    "### F2: Description using very negative attributes (explicit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ba9edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hypothesis = \"That text mentions a negative attribute of [X].\"\n",
    "hypothesis = \"That text describes [X] using very negative attributes.\"\n",
    "func = \"F2: Description using very negative attributes (explicit)\"\n",
    "\n",
    "result = list()\n",
    "for tup in tqdm(df.itertuples(), total=df.shape[0]):\n",
    "    message, functionality, hate_label = tup[1], tup[2], tup[3]\n",
    "    if functionality == func:  # only apply to the target functionality\n",
    "        prob = test_single_hypothesis(message, hypothesis, target_group=target_group)\n",
    "        result.append(int(prob > 0.5))\n",
    "    else:\n",
    "        result.append(-1)\n",
    "df['nli_f2_neg_attr'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f566b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_folder/data_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95ebc3c",
   "metadata": {},
   "source": [
    "### F3: Dehumanisation (explicit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c49fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = \"That text contains dehumanization.\"\n",
    "func = \"F3: Dehumanisation (explicit)\"\n",
    "\n",
    "result = list()\n",
    "for tup in tqdm(df.itertuples(), total=df.shape[0]):\n",
    "    message, functionality, hate_label = tup[1], tup[2], tup[3]\n",
    "    if functionality == func:  # only apply to the target functionality\n",
    "        prob = test_single_hypothesis(message, hypothesis)\n",
    "        result.append(int(prob > 0.5))\n",
    "    else:\n",
    "        result.append(-1)\n",
    "df['nli_f3_dehum'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68c50d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_folder/data_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7312c80c",
   "metadata": {},
   "source": [
    "### F4: Implicit derogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdf8e51-5825-471e-9381-97cc9708d088",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis_explicit = \"That text contains explicit obscene language.\"\n",
    "hypothesis_derogation = \"That text contains derogation\"\n",
    "func = \"F4: Implicit derogation\"\n",
    "\n",
    "result = list()\n",
    "derogation_result = list()\n",
    "for tup in tqdm(df.itertuples(), total=df.shape[0]):\n",
    "    message, functionality, hate_label = tup[1], tup[2], tup[3]\n",
    "    if functionality == func:  # only apply to the target functionality\n",
    "        prob = test_single_hypothesis(message, hypothesis_explicit)\n",
    "        result.append(int(prob < 0.5))\n",
    "        prob = test_single_hypothesis(message, hypothesis_derogation)\n",
    "        derogation_result.append(int(prob > 0.5))\n",
    "    else:\n",
    "        result.append(-1)\n",
    "        derogation_result.append(-1)\n",
    "df['nli_f4_implicit'] = result\n",
    "df['nli_f4_derogation'] = derogation_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46310561",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_folder/data_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb1b47f",
   "metadata": {},
   "source": [
    "### F5: Direct threat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fff468",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = \"That text contains a direct threat.\"\n",
    "func = \"F5: Direct threat\"\n",
    "\n",
    "result = list()\n",
    "for tup in tqdm(df.itertuples(), total=df.shape[0]):\n",
    "    message, functionality, hate_label = tup[1], tup[2], tup[3]\n",
    "    if functionality == func:  # only apply to the target functionality\n",
    "        prob = test_single_hypothesis(message, hypothesis)\n",
    "        result.append(int(prob > 0.5))\n",
    "    else:\n",
    "        result.append(-1)\n",
    "df['nli_f5_dir_threat'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcffe54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_folder/data_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9862e868",
   "metadata": {},
   "source": [
    "### F6: Threat as normative statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3355ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = \"That text contains a threat as normative statement.\"\n",
    "func = \"F6: Threat as normative statement\"\n",
    "\n",
    "result = list()\n",
    "for tup in tqdm(df.itertuples(), total=df.shape[0]):\n",
    "    message, functionality, hate_label = tup[1], tup[2], tup[3]\n",
    "    if functionality == func:  # only apply to the target functionality\n",
    "        prob = test_single_hypothesis(message, hypothesis)\n",
    "        result.append(int(prob > 0.5))\n",
    "    else:\n",
    "        result.append(-1)\n",
    "df['nli_f6_norm_threat'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e438f82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_folder/data_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2952dc",
   "metadata": {},
   "source": [
    "### F7: Hate expressed using slur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e058e3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = \"That text contains a slur referring to [X].\"\n",
    "func = \"F7: Hate expressed using slur\"\n",
    "\n",
    "result = list()\n",
    "for tup in tqdm(df.itertuples(), total=df.shape[0]):\n",
    "    message, functionality, hate_label = tup[1], tup[2], tup[3]\n",
    "    if functionality == func:  # only apply to the target functionality\n",
    "        prob = test_single_hypothesis(message, hypothesis, target_group=target_group)\n",
    "        result.append(int(prob > 0.5))\n",
    "    else:\n",
    "        result.append(-1)\n",
    "df['nli_f7_slur'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8940aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_folder/data_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668cca91",
   "metadata": {},
   "source": [
    "### F9: Reclaimed slurs\n",
    "\n",
    "Using the prompts in the hypothesis engineering paper.\n",
    "\n",
    "```\n",
    "  \"rec_slur\": {\n",
    "    \"myself\": \"This text is about myself.\",\n",
    "    \"us\": \"This text is about us.\",\n",
    "    \"neg-senti\": \"This text has a negative sentiment.\"\n",
    "  }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb95451",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = \"This text is about myself.\"\n",
    "func = \"F9: Reclaimed slurs\"\n",
    "\n",
    "result = list()\n",
    "for tup in tqdm(df.itertuples(), total=df.shape[0]):\n",
    "    message, functionality, hate_label = tup[1], tup[2], tup[3]\n",
    "    if functionality == func:  # only apply to the target functionality\n",
    "        prob = test_single_hypothesis(message, hypothesis)\n",
    "        result.append(int(prob > 0.5))\n",
    "    else:\n",
    "        result.append(-1)\n",
    "df['nli_f9_myself'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed76d47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = \"This text is about us.\"\n",
    "func = \"F9: Reclaimed slurs\"\n",
    "\n",
    "result = list()\n",
    "for tup in tqdm(df.itertuples(), total=df.shape[0]):\n",
    "    message, functionality, hate_label = tup[1], tup[2], tup[3]\n",
    "    if functionality == func:  # only apply to the target functionality\n",
    "        prob = test_single_hypothesis(message, hypothesis)\n",
    "        result.append(int(prob > 0.5))\n",
    "    else:\n",
    "        result.append(-1)\n",
    "df['nli_f9_us'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09593d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = \"This text has a negative sentiment.\"\n",
    "func = \"F9: Reclaimed slurs\"\n",
    "\n",
    "result = list()\n",
    "for tup in tqdm(df.itertuples(), total=df.shape[0]):\n",
    "    message, functionality, hate_label = tup[1], tup[2], tup[3]\n",
    "    if functionality == func:  # only apply to the target functionality\n",
    "        prob = test_single_hypothesis(message, hypothesis)\n",
    "        result.append(int(prob > 0.5))\n",
    "    else:\n",
    "        result.append(-1)\n",
    "df['nli_f9_negative'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef446087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a message is reclaim slur if it is positive or it refers to the speakers own group\n",
    "def aggregate_f9_label(x):\n",
    "    if x['nli_f9_negative'] == -1:\n",
    "        return -1\n",
    "    else:\n",
    "        return int((not x['nli_f9_negative']) or x['nli_f9_myself'] or x['nli_f9_us'])\n",
    "    \n",
    "df['nli_f9_aggregate'] = df.apply(lambda x: aggregate_f9_label(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d74726",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_folder/data_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944b65f3",
   "metadata": {},
   "source": [
    "### F10: Hate expressed using profanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef222df",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = \"That text contains obscene language.\"\n",
    "func = \"F10: Hate expressed using profanity\"\n",
    "\n",
    "result = list()\n",
    "for tup in tqdm(df.itertuples(), total=df.shape[0]):\n",
    "    message, functionality, hate_label = tup[1], tup[2], tup[3]\n",
    "    if functionality == func:  # only apply to the target functionality\n",
    "        prob = test_single_hypothesis(message, hypothesis)\n",
    "        result.append(int(prob > 0.5))\n",
    "    else:\n",
    "        result.append(-1)\n",
    "df['nli_f10_profane'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c43a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_folder/data_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab50b76",
   "metadata": {},
   "source": [
    "### F11: Non-hateful use of profanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c80981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = \"That text contains obscene language.\"\n",
    "func = \"F11: Non-hateful use of profanity\"\n",
    "\n",
    "result = list()\n",
    "for tup in tqdm(df.itertuples(), total=df.shape[0]):\n",
    "    message, functionality, hate_label = tup[1], tup[2], tup[3]\n",
    "    if functionality == func:  # only apply to the target functionality\n",
    "        prob = test_single_hypothesis(message, hypothesis)\n",
    "        result.append(int(prob > 0.5))\n",
    "    else:\n",
    "        result.append(-1)\n",
    "df['nli_f11_profane'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be44367",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_folder/data_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779c29f4",
   "metadata": {},
   "source": [
    "### F12: Hate expressed through reference in subsequent clauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf6f2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = \"That contains hate speech.\"\n",
    "func = \"F12: Hate expressed through reference in subsequent clauses\"\n",
    "\n",
    "result = list()\n",
    "for tup in tqdm(df.itertuples(), total=df.shape[0]):\n",
    "    message, functionality, hate_label = tup[1], tup[2], tup[3]\n",
    "    if functionality == func:  # only apply to the target functionality\n",
    "        if \",\" not in message:  # if has fewer than 2 phrases -> fail\n",
    "            result.append(0)\n",
    "        else:\n",
    "            subsequent_clause = message[message.index(\",\")+1:]\n",
    "            prob = test_single_hypothesis(subsequent_clause, hypothesis)\n",
    "            result.append(int(prob > 0.5))\n",
    "    else:\n",
    "        result.append(-1)\n",
    "df['nli_f12_subsequent_clause_hate'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85286a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_folder/data_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd322d1c",
   "metadata": {},
   "source": [
    "### F13: Hate expressed through reference in subsequent sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9660a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = \"That contains hate speech.\"\n",
    "func = \"F13: Hate expressed through reference in subsequent sentences\"\n",
    "\n",
    "result = list()\n",
    "for tup in tqdm(df.itertuples(), total=df.shape[0]):\n",
    "    message, functionality, hate_label = tup[1], tup[2], tup[3]\n",
    "    if functionality == func:  # only apply to the target functionality\n",
    "        sents = sent_tokenize(message)\n",
    "        if len(sents) < 2:  # if has fewer than 2 sentences -> fail\n",
    "            result.append(0)\n",
    "        else:\n",
    "            subsequent_sent = \" \".join(sents[1:])\n",
    "            prob = test_single_hypothesis(subsequent_sent, hypothesis)\n",
    "            result.append(int(prob > 0.5))\n",
    "    else:\n",
    "        result.append(-1)\n",
    "df['nli_f13_subsequent_sent_hate'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bbf722",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_folder/data_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa01b706",
   "metadata": {},
   "source": [
    "### F14: Hate expressed using negated positive statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9bf907",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = \"That text contains a negation.\"\n",
    "func = \"F14: Hate expressed using negated positive statement\"\n",
    "\n",
    "result = list()\n",
    "for tup in tqdm(df.itertuples(), total=df.shape[0]):\n",
    "    message, functionality, hate_label = tup[1], tup[2], tup[3]\n",
    "    if functionality == func:  # only apply to the target functionality\n",
    "        prob = test_single_hypothesis(message, hypothesis)\n",
    "        result.append(int(prob > 0.5))\n",
    "    else:\n",
    "        result.append(-1)\n",
    "df['nli_f14_negation'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c12145",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = \"That text is a positive statement towards [X].\"\n",
    "func = \"F14: Hate expressed using negated positive statement\"\n",
    "\n",
    "result = list()\n",
    "for tup in tqdm(df.itertuples(), total=df.shape[0]):\n",
    "    message, functionality, hate_label = tup[1], tup[2], tup[3]\n",
    "    if functionality == func:  # only apply to the target functionality\n",
    "        orig_statement =\" \".join([word for word in word_tokenize(message) if word.lower() not in negation_words])\n",
    "        prob = test_single_hypothesis(orig_statement, hypothesis, target_group=target_group)\n",
    "        result.append(int(prob > 0.5))\n",
    "    else:\n",
    "        result.append(-1)\n",
    "df['nli_f14_positive_statement'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542ba7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_folder/data_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354205d9",
   "metadata": {},
   "source": [
    "### F15: Non-hate expressed using negated hateful statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb78642",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = \"That text contains a negation.\"\n",
    "func = \"F15: Non-hate expressed using negated hateful statement\"\n",
    "\n",
    "result = list()\n",
    "for tup in tqdm(df.itertuples(), total=df.shape[0]):\n",
    "    message, functionality, hate_label = tup[1], tup[2], tup[3]\n",
    "    if functionality == func:  # only apply to the target functionality\n",
    "        prob = test_single_hypothesis(message, hypothesis)\n",
    "        result.append(int(prob > 0.5))\n",
    "    else:\n",
    "        result.append(-1)\n",
    "df['nli_f15_negation'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3339a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = \"That text contains hate speech against [X].\"\n",
    "func = \"F15: Non-hate expressed using negated hateful statement\"\n",
    "\n",
    "result = list()\n",
    "for tup in tqdm(df.itertuples(), total=df.shape[0]):\n",
    "    message, functionality, hate_label = tup[1], tup[2], tup[3]\n",
    "    if functionality == func:  # only apply to the target functionality\n",
    "        orig_statement =\" \".join([word for word in word_tokenize(message) if word.lower() not in negation_words])\n",
    "        prob = test_single_hypothesis(orig_statement, hypothesis, target_group=target_group)\n",
    "        result.append(int(prob > 0.5))\n",
    "        #print(f\"{int(prob > 0.5)}\\t{orig_statement}\\t{message}\")\n",
    "    else:\n",
    "        result.append(-1)\n",
    "df['nli_f15_hate_statement'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b281a4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_folder/data_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5658c41",
   "metadata": {},
   "source": [
    "### F16: Hate phrased as a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aab68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = \"That text is a question.\"\n",
    "func = \"F16: Hate phrased as a question\"\n",
    "\n",
    "result = list()\n",
    "for tup in tqdm(df.itertuples(), total=df.shape[0]):\n",
    "    message, functionality, hate_label = tup[1], tup[2], tup[3]\n",
    "    if functionality == func:  # only apply to the target functionality\n",
    "        prob = test_single_hypothesis(message, hypothesis)\n",
    "        result.append(int(prob > 0.5))\n",
    "    else:\n",
    "        result.append(-1)\n",
    "df['nli_f16_question'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7ecfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_folder/data_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dc560f",
   "metadata": {},
   "source": [
    "### F17: Hate phrased as an opinion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33747b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = \"That text is a subjective opinion.\"\n",
    "func = \"F17: Hate phrased as an opinion\"\n",
    "\n",
    "result = list()\n",
    "for tup in tqdm(df.itertuples(), total=df.shape[0]):\n",
    "    message, functionality, hate_label = tup[1], tup[2], tup[3]\n",
    "    if functionality == func:  # only apply to the target functionality\n",
    "        prob = test_single_hypothesis(message, hypothesis)\n",
    "        result.append(int(prob > 0.5))\n",
    "    else:\n",
    "        result.append(-1)\n",
    "df['nli_f17_opinion'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148bc63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_folder/data_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f947a779",
   "metadata": {},
   "source": [
    "### F18: Neutral statements using protected group identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26937dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = \"That text is a very positive statement.\"\n",
    "func = \"F18: Neutral statements using protected group identifier\"\n",
    "\n",
    "result = list()\n",
    "for tup in tqdm(df.itertuples(), total=df.shape[0]):\n",
    "    message, functionality, hate_label = tup[1], tup[2], tup[3]\n",
    "    if functionality == func:  # only apply to the target functionality\n",
    "        prob = test_single_hypothesis(message, hypothesis)\n",
    "        result.append(int(prob < 0.5))\n",
    "    else:\n",
    "        result.append(-1)\n",
    "df['nli_f18_neutral'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af191e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_folder/data_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584182a2",
   "metadata": {},
   "source": [
    "### F19: Positive statements using protected group identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef88368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = \"That text is a positive statement.\"\n",
    "func = \"F19: Positive statements using protected group identifier\"\n",
    "\n",
    "result = list()\n",
    "for tup in tqdm(df.itertuples(), total=df.shape[0]):\n",
    "    message, functionality, hate_label = tup[1], tup[2], tup[3]\n",
    "    if functionality == func:  # only apply to the target functionality\n",
    "        prob = test_single_hypothesis(message, hypothesis)\n",
    "        result.append(int(prob > 0.5))\n",
    "    else:\n",
    "        result.append(-1)\n",
    "df['nli_f19_positive'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb505fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_folder/data_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f5a833",
   "metadata": {},
   "source": [
    "### F20: Denouncements of hate that quote it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453c2481",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_reg = re.compile(r\" [‘“'\\\"](.*?)[”’'\\\"]\")\n",
    "hate_hypothesis = \"That contains hate speech.\"\n",
    "denounce_hypothesis = \"This text supports [X]\"\n",
    "func = \"F20: Denouncements of hate that quote it\"\n",
    "\n",
    "hate_result = list()\n",
    "denounce_result = list()\n",
    "for tup in tqdm(df.itertuples(), total=df.shape[0]):\n",
    "    message, functionality, hate_label = tup[1], tup[2], tup[3]\n",
    "    \n",
    "    if functionality == func:  # only apply to the target functionality\n",
    "        quotes = quote_reg.findall(f\" {message}\")\n",
    "        if len(quotes) == 1:  # contains exactly 1 quote\n",
    "            prob = test_single_hypothesis(quotes[0], hate_hypothesis)\n",
    "            hate_result.append(int(prob > 0.5))\n",
    "            \n",
    "            surround_text = quote_reg.sub(\" [X]\", f\" {message}\").strip()\n",
    "            prob = test_single_hypothesis(surround_text, denounce_hypothesis)\n",
    "            denounce_result.append(int(prob < 0.5))\n",
    "        else:\n",
    "            hate_result.append(0)\n",
    "            denounce_result.append(0)\n",
    "            print(f\"[INFO]: Doesn't contain quote \\t {message}\")\n",
    "    else:\n",
    "        hate_result.append(-1)\n",
    "        denounce_result.append(-1)\n",
    "df['nli_f20_hate_quote'] = hate_result\n",
    "df['nli_f20_denounce'] = denounce_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c13c5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_folder/data_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963daef3-b3ee-44af-b8ce-6bd6c203e5a5",
   "metadata": {},
   "source": [
    "### F21: Denouncements of hate that make direct reference to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3657952d-3bac-4dc7-a5a2-6e443e618f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = \"That text is a denouncement.\"\n",
    "func = \"F21: Denouncements of hate that make direct reference to it\"\n",
    "\n",
    "result = list()\n",
    "for tup in tqdm(df.itertuples(), total=df.shape[0]):\n",
    "    message, functionality, hate_label = tup[1], tup[2], tup[3]\n",
    "    if functionality == func:  # only apply to the target functionality\n",
    "        prob = test_single_hypothesis(message, hypothesis)\n",
    "        result.append(int(prob > 0.5))\n",
    "    else:\n",
    "        result.append(-1)\n",
    "df['nli_f21_denounce'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb1d135-5747-4a95-a8a8-68cb54828038",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_folder/data_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820b3da2-9fe3-4515-a23b-e22b98720dc5",
   "metadata": {},
   "source": [
    "### F22: Abuse targeted at objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f4eaae-b46b-4331-a911-51e0b8fb1f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = \"That text is about a non-human material object.\"\n",
    "func = \"F22: Abuse targeted at objects\"\n",
    "\n",
    "result = list()\n",
    "for tup in tqdm(df.itertuples(), total=df.shape[0]):\n",
    "    message, functionality, hate_label = tup[1], tup[2], tup[3]\n",
    "    if functionality == func:  # only apply to the target functionality\n",
    "        prob = test_single_hypothesis(message, hypothesis)\n",
    "        result.append(int(prob > 0.5))\n",
    "    else:\n",
    "        result.append(-1)\n",
    "df['nli_f22_object'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31272a9e-038d-4b0e-aad7-f2df2319d78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_folder/data_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd64839-ecd1-4f4f-926e-f8b2ce307ffc",
   "metadata": {},
   "source": [
    "### F23: Abuse targeted at individuals (not as member of a prot. group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc964732-88c7-49c3-aac3-a51da85c0bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = \"That text is about you.\"\n",
    "func = \"F23: Abuse targeted at individuals (not as member of a prot. group)\"\n",
    "\n",
    "result = list()\n",
    "for tup in tqdm(df.itertuples(), total=df.shape[0]):\n",
    "    message, functionality, hate_label = tup[1], tup[2], tup[3]\n",
    "    if functionality == func:  # only apply to the target functionality\n",
    "        prob = test_single_hypothesis(message, hypothesis)\n",
    "        result.append(int(prob > 0.5))\n",
    "    else:\n",
    "        result.append(-1)\n",
    "df['nli_f23_you'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38050a3d-876c-46c0-9b50-1952386b5d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_folder/data_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d85eae5-8272-4e1c-8e4e-dd121d8602a1",
   "metadata": {},
   "source": [
    "## 3. Functionality-Level Label Aggregation\n",
    "\n",
    "Aggregate the NLI label based on specific hypothesis tests using predefined rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228c2aec-37e1-4575-a60a-16d730b136e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "functionality2tests = {\n",
    "    \"F1: Expression of strong negative emotions (explicit)\": ['nli_identity', 'nli_f1_neg_emotion'],\n",
    "    \"F2: Description using very negative attributes (explicit)\": ['nli_identity', 'nli_f2_neg_attr'],\n",
    "    \"F3: Dehumanisation (explicit)\": ['nli_identity', 'nli_f3_dehum'],\n",
    "    \"F4: Implicit derogation\": ['nli_identity', 'nli_f4_implicit', 'nli_f4_derogation'],\n",
    "    \"F5: Direct threat\": ['nli_identity', 'nli_f5_dir_threat'],\n",
    "    \"F6: Threat as normative statement\": ['nli_identity', 'nli_f6_norm_threat'],\n",
    "    \"F7: Hate expressed using slur\": ['nli_identity', 'nli_hate', 'nli_f7_slur'],\n",
    "    \"F8: Non-hateful homonyms of slurs\": ['NOT nli_identity', 'NOT nli_hate'],\n",
    "    \"F9: Reclaimed slurs\": ['nli_identity', 'nli_f9_aggregate'],\n",
    "    \"F10: Hate expressed using profanity\": ['nli_identity', 'nli_hate', 'nli_f10_profane'],\n",
    "    \"F11: Non-hateful use of profanity\": ['NOT nli_identity', 'nli_f11_profane'],\n",
    "    \"F12: Hate expressed through reference in subsequent clauses\": ['nli_identity', 'nli_hate', 'nli_f12_subsequent_clause_hate'],\n",
    "    \"F13: Hate expressed through reference in subsequent sentences\": ['nli_identity', 'nli_hate', 'nli_f13_subsequent_sent_hate'],\n",
    "    \"F14: Hate expressed using negated positive statement\": ['nli_identity', 'nli_f14_negation', 'nli_f14_positive_statement'],\n",
    "    \"F15: Non-hate expressed using negated hateful statement\": ['nli_identity', 'nli_f15_negation', 'nli_f15_hate_statement'],\n",
    "    \"F16: Hate phrased as a question\": ['nli_identity', 'nli_hate', 'nli_f16_question'],\n",
    "    \"F17: Hate phrased as an opinion\": ['nli_identity', 'nli_hate', 'nli_f17_opinion'],\n",
    "    \"F18: Neutral statements using protected group identifier\": ['nli_identity','NOT nli_hate', 'nli_f18_neutral'],\n",
    "    \"F19: Positive statements using protected group identifier\": ['nli_identity', 'nli_f19_positive'],\n",
    "    \"F20: Denouncements of hate that quote it\": ['nli_identity', 'nli_f20_hate_quote', 'nli_f20_denounce'],\n",
    "    \"F21: Denouncements of hate that make direct reference to it\": ['nli_identity', 'nli_f21_denounce'],\n",
    "    \"F22: Abuse targeted at objects\": ['NOT nli_identity', 'nli_hate', 'nli_f22_object'],\n",
    "    \"F23: Abuse targeted at individuals (not as member of a prot. group)\": ['NOT nli_identity', 'nli_hate', 'nli_f23_you'],\n",
    "    \"F24: Abuse targeted at non-protected groups (e.g. professions)\": ['NOT nli_identity', 'nli_hate'],\n",
    "    \"F25-29: Spelling variation\": ['nli_identity', 'nli_hate']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c759ed0b-f070-45f3-9bef-b311f0e2f9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_label(x):\n",
    "    tests = functionality2tests[x['functionality']]\n",
    "    pass_test = True\n",
    "    for test in tests:\n",
    "        answer = 1\n",
    "        if test.startswith(\"NOT\"):\n",
    "            answer = 0\n",
    "            test = test.split(\" \")[-1]\n",
    "        if x[test] < 0:\n",
    "            print(f\"Sth is wrong. {x}\")\n",
    "        elif x[test] != answer:\n",
    "            pass_test = False\n",
    "            break\n",
    "    return int(pass_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4505eada-68bc-4d93-b002-f3e3afb9aa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nli_pass_test'] = df.apply(lambda x: aggregate_label(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d01367-2f6d-4d0f-9519-bd6adcdf3a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['functionality', 'nli_pass_test', 'hate_label']].groupby(['functionality'], sort=False).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeb7eae-c097-43f8-b32c-334398dc31b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_folder/data_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f846aa",
   "metadata": {},
   "source": [
    "## Appendix: Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a58d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"functionality\", sort=False).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74006ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['nli_hate_label']==df['hate_label']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2514f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['nli_hate']==df['hate_label']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b940e0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['nli_hate_label']==df['hate_label']].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
